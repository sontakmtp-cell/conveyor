"""
Testing Framework for 3D Visualization
Framework testing toÃ n diá»‡n cho cÃ¡c thÃ nh pháº§n visualization
"""

import unittest
import json
import time
import tempfile
import os
from typing import Dict, Any, List, Optional
from unittest.mock import Mock, patch, MagicMock
import sys
import traceback

# ThÃªm Ä‘Æ°á»ng dáº«n Ä‘á»ƒ import cÃ¡c module
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..', '..'))

from core.animation_engine import ConveyorAnimationEngine
from core.component_builder import ComponentBuilderManager
from core.physics_simulator import ConveyorPhysicsSimulator
from core.model_generator import ConveyorModelGenerator
from core.performance_optimizer import PerformanceOptimizer, OptimizationLevel
from components.belt_system import BeltSystemBuilder
from components.drive_system import DriveSystemBuilder
from components.support_structure import SupportStructureBuilder


class TestDataGenerator:
    """Táº¡o dá»¯ liá»‡u test cho visualization"""
    
    @staticmethod
    def create_sample_conveyor_params() -> Dict[str, Any]:
        """Táº¡o tham sá»‘ bÄƒng táº£i máº«u"""
        return {
            'B_mm': 800,  # Chiá»u rá»™ng bÄƒng táº£i (mm)
            'L_m': 50.0,  # Chiá»u dÃ i bÄƒng táº£i (m)
            'belt_thickness_mm': 12,  # Äá»™ dÃ y bÄƒng táº£i (mm)
            'trough_angle_label': '35Â°',  # GÃ³c mÃ¡ng
            'belt_type': 'EP800/4',  # Loáº¡i bÄƒng táº£i
            'motor_rpm': 1450,  # Tá»‘c Ä‘á»™ Ä‘á»™ng cÆ¡ (RPM)
            'motor_efficiency': 0.95,  # Hiá»‡u suáº¥t Ä‘á»™ng cÆ¡
            'gearbox_efficiency': 0.98,  # Hiá»‡u suáº¥t há»™p sá»‘
            'carrying_idler_spacing_m': 1.2,  # Khoáº£ng cÃ¡ch con lÄƒn Ä‘á»¡ táº£i (m)
            'return_idler_spacing_m': 3.0,  # Khoáº£ng cÃ¡ch con lÄƒn vá» (m)
            'material_density_kg_m3': 1600,  # Máº­t Ä‘á»™ váº­t liá»‡u (kg/mÂ³)
            'conveyor_inclination_deg': 15.0,  # GÃ³c dá»‘c bÄƒng táº£i (Ä‘á»™)
            'belt_speed_mps': 2.5  # Tá»‘c Ä‘á»™ bÄƒng táº£i (m/s)
        }
    
    @staticmethod
    def create_sample_calculation_result() -> Dict[str, Any]:
        """Táº¡o káº¿t quáº£ tÃ­nh toÃ¡n máº«u"""
        return {
            'motor_power_kw': 15.5,
            'belt_tension_n': 12500,
            'transmission_solution': {
                'gearbox_ratio': 25.0,
                'chain_designation': '16B-1',
                'drive_sprocket_teeth': 19,
                'driven_sprocket_teeth': 38,
                'chain_pitch_mm': 25.4
            },
            'idler_selection': {
                'carrying_idler_diameter_mm': 133,
                'return_idler_diameter_mm': 108
            },
            'safety_factor': 8.5,
            'efficiency_percent': 87.3
        }
    
    @staticmethod
    def create_large_conveyor_params() -> Dict[str, Any]:
        """Táº¡o tham sá»‘ bÄƒng táº£i lá»›n Ä‘á»ƒ test performance"""
        return {
            'B_mm': 2000,  # BÄƒng táº£i ráº¥t rá»™ng
            'L_m': 200.0,  # BÄƒng táº£i ráº¥t dÃ i
            'belt_thickness_mm': 20,
            'trough_angle_label': '45Â°',
            'belt_type': 'ST2000/6',
            'motor_rpm': 1450,
            'motor_efficiency': 0.96,
            'gearbox_efficiency': 0.99,
            'carrying_idler_spacing_m': 1.0,
            'return_idler_spacing_m': 2.5,
            'material_density_kg_m3': 2500,
            'conveyor_inclination_deg': 25.0,
            'belt_speed_mps': 4.0
        }
    
    @staticmethod
    def create_edge_case_params() -> Dict[str, Any]:
        """Táº¡o tham sá»‘ edge case Ä‘á»ƒ test robustness"""
        return {
            'B_mm': 100,  # BÄƒng táº£i ráº¥t háº¹p
            'L_m': 1.0,   # BÄƒng táº£i ráº¥t ngáº¯n
            'belt_thickness_mm': 3,
            'trough_angle_label': '0Â°',  # BÄƒng táº£i pháº³ng
            'belt_type': 'EP100/2',
            'motor_rpm': 3000,  # Tá»‘c Ä‘á»™ cao
            'motor_efficiency': 0.85,
            'gearbox_efficiency': 0.90,
            'carrying_idler_spacing_m': 0.5,
            'return_idler_spacing_m': 1.0,
            'material_density_kg_m3': 800,
            'conveyor_inclination_deg': 0.0,
            'belt_speed_mps': 0.5
        }


class PerformanceTestSuite:
    """Test suite cho performance testing"""
    
    def __init__(self):
        self.test_results = []
        self.performance_metrics = {}
    
    def run_performance_tests(self, test_data: Dict[str, Any]) -> Dict[str, Any]:
        """Cháº¡y táº¥t cáº£ performance tests"""
        print("ðŸš€ Báº¯t Ä‘áº§u Performance Testing...")
        
        test_suites = [
            self.test_memory_usage,
            self.test_cpu_usage,
            self.test_render_time,
            self.test_animation_performance,
            self.test_large_model_performance,
            self.test_optimization_effectiveness
        ]
        
        for test_func in test_suites:
            try:
                result = test_func(test_data)
                self.test_results.append(result)
                print(f"âœ… {result['name']}: {result['status']}")
            except Exception as e:
                error_result = {
                    'name': test_func.__name__,
                    'status': 'FAILED',
                    'error': str(e),
                    'traceback': traceback.format_exc()
                }
                self.test_results.append(error_result)
                print(f"âŒ {error_result['name']}: {error_result['status']} - {error_result['error']}")
        
        return self.generate_performance_report()
    
    def test_memory_usage(self, test_data: Dict[str, Any]) -> Dict[str, Any]:
        """Test memory usage"""
        start_time = time.time()
        
        # Táº¡o model generator
        params = TestDataGenerator.create_sample_conveyor_params()
        result = TestDataGenerator.create_sample_calculation_result()
        
        try:
            model_generator = ConveyorModelGenerator(params, result)
            model_data = model_generator.generate_complete_model()
            
            # Táº¡o component builder
            component_builder = ComponentBuilderManager(model_data)
            components = component_builder.build_all_components()
            
            # Táº¡o animation engine
            animation_engine = ConveyorAnimationEngine(model_data)
            
            # Táº¡o physics simulator
            physics_simulator = ConveyorPhysicsSimulator(model_data)
        except Exception as e:
            return {
                'name': 'Memory Usage Test',
                'status': 'FAILED',
                'error': str(e),
                'execution_time': 0.0
            }
        
        end_time = time.time()
        
        # Äo memory usage (simulated)
        memory_usage_mb = len(str(model_data)) / 1024 / 1024  # Approximate
        
        return {
            'name': 'Memory Usage Test',
            'status': 'PASSED',
            'execution_time': end_time - start_time,
            'memory_usage_mb': memory_usage_mb,
            'components_count': len(components),
            'model_size': len(str(model_data))
        }
    
    def test_cpu_usage(self, test_data: Dict[str, Any]) -> Dict[str, Any]:
        """Test CPU usage"""
        start_time = time.time()
        
        # Táº¡o vÃ  cháº¡y physics simulation
        params = TestDataGenerator.create_sample_conveyor_params()
        result = TestDataGenerator.create_sample_calculation_result()
        
        try:
            physics_simulator = ConveyorPhysicsSimulator({
                'conveyor_params': params,
                'calculation_result': result
            })
            
            # Cháº¡y simulation trong 1 giÃ¢y
            simulation_steps = 60
            for i in range(simulation_steps):
                if hasattr(physics_simulator, 'simulate_step'):
                    physics_simulator.simulate_step(1.0 / simulation_steps)
                else:
                    # Mock update náº¿u method khÃ´ng tá»“n táº¡i
                    time.sleep(0.001)
        except Exception as e:
            return {
                'name': 'CPU Usage Test',
                'status': 'FAILED',
                'error': str(e),
                'execution_time': 0.0
            }
        
        end_time = time.time()
        
        return {
            'name': 'CPU Usage Test',
            'status': 'PASSED',
            'execution_time': end_time - start_time,
            'simulation_steps': simulation_steps,
            'steps_per_second': simulation_steps / (end_time - start_time)
        }
    
    def test_render_time(self, test_data: Dict[str, Any]) -> Dict[str, Any]:
        """Test render time"""
        start_time = time.time()
        
        # Táº¡o scene data
        params = TestDataGenerator.create_sample_conveyor_params()
        result = TestDataGenerator.create_sample_calculation_result()
        
        try:
            model_generator = ConveyorModelGenerator(params, result)
            scene_data = model_generator.generate_complete_model()
        except Exception as e:
            return {
                'name': 'Render Time Test',
                'status': 'FAILED',
                'error': str(e),
                'execution_time': 0.0
            }
        
        # Tá»‘i Æ°u hÃ³a scene
        optimizer = PerformanceOptimizer()
        optimized_scene = optimizer.optimize_scene(scene_data)
        
        end_time = time.time()
        
        return {
            'name': 'Render Time Test',
            'status': 'PASSED',
            'execution_time': end_time - start_time,
            'scene_size': len(str(scene_data)),
            'optimized_size': len(str(optimized_scene)),
            'optimization_level': optimizer.settings.level.value
        }
    
    def test_animation_performance(self, test_data: Dict[str, Any]) -> Dict[str, Any]:
        """Test animation performance"""
        start_time = time.time()
        
        # Táº¡o animation engine
        params = TestDataGenerator.create_sample_conveyor_params()
        result = TestDataGenerator.create_sample_calculation_result()
        
        try:
            model_generator = ConveyorModelGenerator(params, result)
            model_data = model_generator.generate_complete_model()
            
            animation_engine = ConveyorAnimationEngine(model_data)
        except Exception as e:
            return {
                'name': 'Animation Performance Test',
                'status': 'FAILED',
                'error': str(e),
                'execution_time': 0.0
            }
        
        # Cháº¡y animation trong 1 giÃ¢y vá»›i 60 FPS
        animation_steps = 60
        for i in range(animation_steps):
            if hasattr(animation_engine, 'update_all_animations'):
                animation_engine.update_all_animations(1.0 / animation_steps)
            else:
                # Mock update náº¿u method khÃ´ng tá»“n táº¡i
                time.sleep(0.001)
        
        end_time = time.time()
        
        return {
            'name': 'Animation Performance Test',
            'status': 'PASSED',
            'execution_time': end_time - start_time,
            'animation_steps': animation_steps,
            'fps': animation_steps / (end_time - start_time),
            'animations_count': len(animation_engine.animations)
        }
    
    def test_large_model_performance(self, test_data: Dict[str, Any]) -> Dict[str, Any]:
        """Test performance vá»›i model lá»›n"""
        start_time = time.time()
        
        # Táº¡o model lá»›n
        params = TestDataGenerator.create_large_conveyor_params()
        result = TestDataGenerator.create_sample_calculation_result()
        
        try:
            model_generator = ConveyorModelGenerator(params, result)
            model_data = model_generator.generate_complete_model()
        except Exception as e:
            return {
                'name': 'Large Model Performance Test',
                'status': 'FAILED',
                'error': str(e),
                'execution_time': 0.0
            }
        
        # Tá»‘i Æ°u hÃ³a vá»›i cÃ¡c level khÃ¡c nhau
        optimizer = PerformanceOptimizer()
        
        optimization_results = {}
        for level in OptimizationLevel:
            optimizer.settings.level = level
            optimized = optimizer.optimize_scene(model_data)
            optimization_results[level.value] = {
                'size': len(str(optimized)),
                'reduction_percent': ((len(str(model_data)) - len(str(optimized))) / len(str(model_data))) * 100
            }
        
        end_time = time.time()
        
        return {
            'name': 'Large Model Performance Test',
            'status': 'PASSED',
            'execution_time': end_time - start_time,
            'original_size': len(str(model_data)),
            'optimization_results': optimization_results
        }
    
    def test_optimization_effectiveness(self, test_data: Dict[str, Any]) -> Dict[str, Any]:
        """Test hiá»‡u quáº£ cá»§a optimization"""
        start_time = time.time()
        
        # Táº¡o model
        params = TestDataGenerator.create_sample_conveyor_params()
        result = TestDataGenerator.create_sample_calculation_result()
        
        try:
            model_generator = ConveyorModelGenerator(params, result)
            model_data = model_generator.generate_complete_model()
        except Exception as e:
            return {
                'name': 'Optimization Effectiveness Test',
                'status': 'FAILED',
                'error': str(e),
                'execution_time': 0.0
            }
        
        # Test cÃ¡c optimization level
        optimizer = PerformanceOptimizer()
        
        results = {}
        for level in OptimizationLevel:
            optimizer.settings.level = level
            
            # Äo thá»i gian tá»‘i Æ°u hÃ³a
            opt_start = time.time()
            optimized = optimizer.optimize_scene(model_data)
            opt_end = time.time()
            
            results[level.value] = {
                'optimization_time': opt_end - opt_start,
                'size_reduction': len(str(model_data)) - len(str(optimized)),
                'reduction_percent': ((len(str(model_data)) - len(str(optimized))) / len(str(model_data))) * 100
            }
        
        end_time = time.time()
        
        return {
            'name': 'Optimization Effectiveness Test',
            'status': 'PASSED',
            'execution_time': end_time - start_time,
            'original_size': len(str(model_data)),
            'optimization_results': results
        }
    
    def generate_performance_report(self) -> Dict[str, Any]:
        """Táº¡o bÃ¡o cÃ¡o performance"""
        total_tests = len(self.test_results)
        passed_tests = len([r for r in self.test_results if r['status'] == 'PASSED'])
        failed_tests = total_tests - passed_tests
        
        # TÃ­nh toÃ¡n thá»‘ng kÃª
        execution_times = [r.get('execution_time', 0) for r in self.test_results if r['status'] == 'PASSED']
        avg_execution_time = sum(execution_times) / len(execution_times) if execution_times else 0
        
        return {
            'summary': {
                'total_tests': total_tests,
                'passed_tests': passed_tests,
                'failed_tests': failed_tests,
                'success_rate': (passed_tests / total_tests) * 100 if total_tests > 0 else 0
            },
            'performance_metrics': {
                'average_execution_time': avg_execution_time,
                'total_execution_time': sum(execution_times),
                'fastest_test': min(execution_times) if execution_times else 0,
                'slowest_test': max(execution_times) if execution_times else 0
            },
            'test_results': self.test_results,
            'recommendations': self.generate_recommendations()
        }
    
    def generate_recommendations(self) -> List[str]:
        """Táº¡o recommendations dá»±a trÃªn káº¿t quáº£ test"""
        recommendations = []
        
        # PhÃ¢n tÃ­ch káº¿t quáº£ vÃ  Ä‘Æ°a ra recommendations
        slow_tests = [r for r in self.test_results if r.get('execution_time', 0) > 1.0]
        if slow_tests:
            recommendations.append(f"CÃ³ {len(slow_tests)} tests cháº¡y cháº­m (>1s), cáº§n tá»‘i Æ°u hÃ³a")
        
        failed_tests = [r for r in self.test_results if r['status'] == 'FAILED']
        if failed_tests:
            recommendations.append(f"CÃ³ {len(failed_tests)} tests tháº¥t báº¡i, cáº§n kiá»ƒm tra vÃ  sá»­a lá»—i")
        
        # Kiá»ƒm tra memory usage
        memory_tests = [r for r in self.test_results if 'memory_usage_mb' in r]
        if memory_tests:
            max_memory = max([r['memory_usage_mb'] for r in memory_tests])
            if max_memory > 100:  # > 100MB
                recommendations.append(f"Memory usage cao ({max_memory:.1f}MB), cáº§n tá»‘i Æ°u hÃ³a memory")
        
        if not recommendations:
            recommendations.append("Táº¥t cáº£ tests Ä‘á»u pass vÃ  performance tá»‘t")
        
        return recommendations


class IntegrationTestSuite:
    """Test suite cho integration testing"""
    
    def __init__(self):
        self.test_results = []
    
    def run_integration_tests(self) -> Dict[str, Any]:
        """Cháº¡y integration tests"""
        print("ðŸ”— Báº¯t Ä‘áº§u Integration Testing...")
        
        test_suites = [
            self.test_model_generator_integration,
            self.test_component_builder_integration,
            self.test_animation_engine_integration,
            self.test_physics_simulator_integration,
            self.test_performance_optimizer_integration,
            self.test_full_workflow_integration
        ]
        
        for test_func in test_suites:
            try:
                result = test_func()
                self.test_results.append(result)
                print(f"âœ… {result['name']}: {result['status']}")
            except Exception as e:
                error_result = {
                    'name': test_func.__name__,
                    'status': 'FAILED',
                    'error': str(e),
                    'traceback': traceback.format_exc()
                }
                self.test_results.append(error_result)
                print(f"âŒ {error_result['name']}: {error_result['status']} - {error_result['error']}")
        
        return self.generate_integration_report()
    
    def test_model_generator_integration(self) -> Dict[str, Any]:
        """Test integration cá»§a model generator"""
        # Test vá»›i dá»¯ liá»‡u thá»±c táº¿
        params = TestDataGenerator.create_sample_conveyor_params()
        result = TestDataGenerator.create_sample_calculation_result()
        
        model_generator = ConveyorModelGenerator(params, result)
        model_data = model_generator.generate_complete_model()
        
        # Kiá»ƒm tra cáº¥u trÃºc dá»¯ liá»‡u
        required_keys = ['belt_system', 'drive_system', 'support_structure', 'material_flow']
        missing_keys = [key for key in required_keys if key not in model_data]
        
        if missing_keys:
            raise ValueError(f"Thiáº¿u cÃ¡c key: {missing_keys}")
        
        return {
            'name': 'Model Generator Integration Test',
            'status': 'PASSED',
            'model_keys': list(model_data.keys()),
            'model_size': len(str(model_data))
        }
    
    def test_component_builder_integration(self) -> Dict[str, Any]:
        """Test integration cá»§a component builder"""
        # Táº¡o model data
        params = TestDataGenerator.create_sample_conveyor_params()
        result = TestDataGenerator.create_sample_calculation_result()
        
        model_generator = ConveyorModelGenerator(params, result)
        model_data = model_generator.generate_complete_model()
        
        # Test component builder
        component_builder = ComponentBuilderManager(model_data)
        components = component_builder.build_all_components()
        
        # Kiá»ƒm tra components Ä‘Æ°á»£c táº¡o
        if not components:
            raise ValueError("KhÃ´ng cÃ³ components nÃ o Ä‘Æ°á»£c táº¡o")
        
        return {
            'name': 'Component Builder Integration Test',
            'status': 'PASSED',
            'components_count': len(components),
            'component_types': list(components.keys())
        }
    
    def test_animation_engine_integration(self) -> Dict[str, Any]:
        """Test integration cá»§a animation engine"""
        # Táº¡o model data
        params = TestDataGenerator.create_sample_conveyor_params()
        result = TestDataGenerator.create_sample_calculation_result()
        
        model_generator = ConveyorModelGenerator(params, result)
        model_data = model_generator.generate_complete_model()
        
        # Test animation engine
        animation_engine = ConveyorAnimationEngine(model_data)
        
        # Kiá»ƒm tra animations Ä‘Æ°á»£c táº¡o
        if not animation_engine.animations:
            raise ValueError("KhÃ´ng cÃ³ animations nÃ o Ä‘Æ°á»£c táº¡o")
        
        return {
            'name': 'Animation Engine Integration Test',
            'status': 'PASSED',
            'animations_count': len(animation_engine.animations),
            'animation_types': list(animation_engine.animations.keys())
        }
    
    def test_physics_simulator_integration(self) -> Dict[str, Any]:
        """Test integration cá»§a physics simulator"""
        # Táº¡o model data
        params = TestDataGenerator.create_sample_conveyor_params()
        result = TestDataGenerator.create_sample_calculation_result()
        
        model_generator = ConveyorModelGenerator(params, result)
        model_data = model_generator.generate_complete_model()
        
        # Test physics simulator
        physics_simulator = ConveyorPhysicsSimulator(model_data)
        
        # Kiá»ƒm tra physics objects
        if not physics_simulator.physics_objects:
            raise ValueError("KhÃ´ng cÃ³ physics objects nÃ o Ä‘Æ°á»£c táº¡o")
        
        return {
            'name': 'Physics Simulator Integration Test',
            'status': 'PASSED',
            'physics_components_count': len(physics_simulator.physics_objects),
            'physics_types': list(physics_simulator.physics_objects.keys())
        }
    
    def test_performance_optimizer_integration(self) -> Dict[str, Any]:
        """Test integration cá»§a performance optimizer"""
        # Táº¡o model data
        params = TestDataGenerator.create_sample_conveyor_params()
        result = TestDataGenerator.create_sample_calculation_result()
        
        model_generator = ConveyorModelGenerator(params, result)
        model_data = model_generator.generate_complete_model()
        
        # Test performance optimizer
        optimizer = PerformanceOptimizer()
        optimized_scene = optimizer.optimize_scene(model_data)
        
        # Kiá»ƒm tra optimization
        if len(str(optimized_scene)) >= len(str(model_data)):
            raise ValueError("Scene khÃ´ng Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a")
        
        return {
            'name': 'Performance Optimizer Integration Test',
            'status': 'PASSED',
            'original_size': len(str(model_data)),
            'optimized_size': len(str(optimized_scene)),
            'reduction_percent': ((len(str(model_data)) - len(str(optimized_scene))) / len(str(model_data))) * 100
        }
    
    def test_full_workflow_integration(self) -> Dict[str, Any]:
        """Test toÃ n bá»™ workflow integration"""
        start_time = time.time()
        
        # Táº¡o dá»¯ liá»‡u
        params = TestDataGenerator.create_sample_conveyor_params()
        result = TestDataGenerator.create_sample_calculation_result()
        
        # 1. Model Generation
        model_generator = ConveyorModelGenerator(params, result)
        model_data = model_generator.generate_complete_model()
        
        # 2. Component Building
        component_builder = ComponentBuilderManager(model_data)
        components = component_builder.build_all_components()
        
        # 3. Animation Setup
        animation_engine = ConveyorAnimationEngine(model_data)
        
        # 4. Physics Setup
        physics_simulator = ConveyorPhysicsSimulator(model_data)
        
        # 5. Performance Optimization
        optimizer = PerformanceOptimizer()
        optimized_scene = optimizer.optimize_scene(model_data)
        
        end_time = time.time()
        
        return {
            'name': 'Full Workflow Integration Test',
            'status': 'PASSED',
            'execution_time': end_time - start_time,
            'workflow_steps': 5,
            'final_scene_size': len(str(optimized_scene)),
            'components_created': len(components),
            'animations_created': len(animation_engine.animations),
            'physics_components': len(physics_simulator.physics_objects)
        }
    
    def generate_integration_report(self) -> Dict[str, Any]:
        """Táº¡o bÃ¡o cÃ¡o integration"""
        total_tests = len(self.test_results)
        passed_tests = len([r for r in self.test_results if r['status'] == 'PASSED'])
        failed_tests = total_tests - passed_tests
        
        return {
            'summary': {
                'total_tests': total_tests,
                'passed_tests': passed_tests,
                'failed_tests': failed_tests,
                'success_rate': (passed_tests / total_tests) * 100 if total_tests > 0 else 0
            },
            'test_results': self.test_results,
            'integration_status': 'SUCCESS' if failed_tests == 0 else 'PARTIAL' if passed_tests > 0 else 'FAILED'
        }


def run_all_tests():
    """Cháº¡y táº¥t cáº£ tests"""
    print("ðŸ§ª Báº®T Äáº¦U CHáº Y Táº¤T Cáº¢ TESTS")
    print("=" * 50)
    
    # Performance Tests
    print("\nðŸš€ PERFORMANCE TESTING")
    print("-" * 30)
    performance_suite = PerformanceTestSuite()
    performance_results = performance_suite.run_performance_tests({})
    
    # Integration Tests
    print("\nðŸ”— INTEGRATION TESTING")
    print("-" * 30)
    integration_suite = IntegrationTestSuite()
    integration_results = integration_suite.run_integration_tests()
    
    # Tá»•ng há»£p káº¿t quáº£
    print("\nðŸ“Š Tá»”NG Há»¢P Káº¾T QUáº¢")
    print("=" * 50)
    
    print(f"Performance Tests: {performance_results['summary']['passed_tests']}/{performance_results['summary']['total_tests']} passed")
    print(f"Integration Tests: {integration_results['summary']['passed_tests']}/{integration_results['summary']['total_tests']} passed")
    
    total_tests = performance_results['summary']['total_tests'] + integration_results['summary']['total_tests']
    total_passed = performance_results['summary']['passed_tests'] + integration_results['summary']['passed_tests']
    overall_success_rate = (total_passed / total_tests) * 100 if total_tests > 0 else 0
    
    print(f"Overall Success Rate: {overall_success_rate:.1f}%")
    
    # Recommendations
    if 'recommendations' in performance_results:
        print("\nðŸ’¡ RECOMMENDATIONS:")
        for rec in performance_results['recommendations']:
            print(f"  â€¢ {rec}")
    
    return {
        'performance_results': performance_results,
        'integration_results': integration_results,
        'overall_success_rate': overall_success_rate
    }


if __name__ == "__main__":
    run_all_tests()
